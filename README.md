This is a fruit of my college essay which required me to analyse the demand patterns of flight services in Brazil. The database provided can be found, as of this date, in https://transparencia.infraero.gov.br/estatisticas/ . Unfortunately, unless you want to program a scrapper for doing the job, all this data must be downloaded on a file per file basis, and there is a file per month since january 2012. However, I wrote an algorithm that translates all these data into one only netcdf file, for the sake of better data import by others and myself in the future. This agorithm is included in this repsitory, for the sake of reproducibility of results, is called infraero_excel2netcdf.py, and needs as input only the following path to a directory structure:

root
    year*
        file*

Note that all downloaded files have their original names preserved in order for the extraction algorithm to work.

About the data from the database provided: it is consisted of monthly (self-?)reports cumulated values of departures and arrivals for aircraft, cargo, mail and passengers in each airport registered in Brazil (and operating at that date). These values are further separated by the local status of flight, which may be one of "regular national", "regular regional", "regular international", "regular cabotage", "irregular national" and "irregular international". Regular cabotage actually only applies as an option to passenger flights; and, besides departures and arrivals, mail flights also hold the orientation option "transit", which I have no idea what means. The data, it should be noted, is presented in a very incosistent way, such that files from a certain date threshold are all xlsm and, before, xls. Furthermore, each year randomly assigns a name extension to the file besides month name, and airports sometimes have their name values given as a four digit string, while in others their names are extended. Finally, upon careful examination of the data actually contained in the original spreadsheets, it is noticeable that some airports strangely exhibit the behavior of having positive numbers of departures and arrivals only for a specific local status in a period and, in another period, only for a different specific local status (the case of SBSP). This drives me to reject local status as a relevant dimension for the analysis of the data content, however it is maintained as output in my data extraction algorithm.

About the data extraction algorithm: my choice towards dealing with these data was translating it from the spreadsheet pivot table format to a multidimensional datacube in the netcdf format. The convenience of the netcdf format is due to the feature-rich, low-entry-difficult and extensively maintained python library "xarray". Other qualities of netcdf, which are applicable to both netcdf and hdf5, are as follows: these formats are binary data representations of multidimensional arrays, constructed with the intention of easy of use for data scientists; as such, it is scalable both in terms of manipulation speed performance and storage space. The low space consumption is specially interesting to me, due to the fact that I want to make the created netcdf file, together with precomputed statistics, available in a public website for visualisation by other scientists.

-,-,-,-,-,-,-,-,

Initially, I didn't intend to make this repository available until the project was done. However, as I have begun a scientific iniciation in a topic unrelated to airflights, I have lost some of my initial interest in this project, altogether with forgetting about what exactly I planned to do and the progress states of it. So, in order not to suddenly forget about it and accidentally delete the whole thing, I decided to put it in a github repository.

The current progress is as follows: the extraction algorithm is done and working free of bugs. However, I still want to verify if the netcdf file generated by the xarray library is space efficient, since there are some dimensions ("cabotage" and "transit") that only form nodes with specific local status dimensions ("passengers" and "mail", respectively). This is initially for the sake of learning, because, regardless of hypothetical storage space optimisation, currently the output filke is only 2.3 MB. A test I've thought of was changing the extraction algorithm so as to deconsider the "cabotage" and/or "transit" dimensions and verify if the space occupied decreases linearly (indicating that dummy nodes were actually occupying space) or in a smaller scale (indicating that dummy nodes weren't actually put in the file). I don't recall why I had suspicions of poor storage space inneficiency, but I want to register this anyway. Also, I still need to do proper analysis of the data and validate my initial assumptions that the MLR succesfully applied to the SBSP airport also applies as a demand prediction tool to other airports. Alongside with other relevant statistics I may find, I shall then ship it, perhaps in an XML file, into the HTML that will be provided as webpage to other researchers and myself. Currently, I am enamorated with the plotly library for javascript, but I am not sure if it provides the best means to dynamic graph drawing, which is what I intend by adding the MLR model results rather then the predicted date values by it.